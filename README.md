# 数字信号处理大作业任务一

## 项目函数结构与使用说明

本项目([github链接](https://github.com/plantman123/MFCC.git))实现了一个基于 MFCC 特征和多种相似度度量（DTW, Cosine, L2）的音频分类系统，主要针对 ESC-50 数据集。项目包含核心信号处理算法的手动实现（FFT, STFT, DCT）以及 CUDA 加速支持。

### 文件结构

```text
./
├── dsp/                    # 核心信号处理模块
│   ├── fft.py              # FFT算法实现 (递归与迭代双版本)
│   ├── stft.py             # 短时傅里叶变换实现
│   └─── mfcc.py            # MFCC特征提取函数
├── features/               # 特征存储/读取文件夹
├── results_hit/            # top-N命中评估
├── results_score/          # 打分评估
├── similarity/
│   └── similarity.py       # 相似度函数
├── function.py             # 辅助函数
├── main.py                 # 主程序 (特征提取与评估)
└── run.sh                  # 运行脚本
```

### 核心函数说明

*   **`dsp/mfcc.py`**:
    *   `mfcc(...)`: 完整的 MFCC 特征提取流程，流程为预加重、分帧、加窗、STFT、Mel 滤波、DCT。
    *   `mel_filterbank(...)`: 生成 Mel 三角滤波器组。
    *   `dct(...)`: 离散余弦变换实现。
*   **`function.py`**:
    *   `load_esc50()`: 加载 ESC-50 数据集元数据。
    *   `classification(...)`: 基于相似度得分进行计算分数进行分类（类似于top1）。
    *   `evaluate(...)`: 多进程并行评估模型准确率。

### 使用说明

**基本运行：**
```bash
# 运行主程序，默认使用 DTW，k=5
python3 main.py --frame_time 0.025 --hop_time 0.010 --sim_mode DTW --k 5
# 或 ./run.sh
```
---

## 实验结果 (Hit & Score)

### 结果展示
本实验在 ESC-50 数据集上进行，对比了不同相似度度量方法在不同帧长([40, 25, 15]ms)和帧移([20, 10, 5]ms)下的准确率表现。

**Top10-Hit-Accuracy**
| Metric | DTW | Cosine  | L2 |
| :--- | :---: | :---: | :---: |
| **(40, 20) ms** | 56.75% | 40.50% | 34.75% |
| **(25, 10) ms** | 55.75% | 40.00% | 35.00% |
| **(15, 05) ms** | **57.00%** | 39.25% | 34.75% |


**Top20-Hit-Accuracy**
| Metric | DTW | Cosine  | L2 |
| :--- | :---: | :---: | :---: |
| **(40, 20) ms** | **68.00%** | 53.25% | 45.75% |
| **(25, 10) ms** | 67.25% | 52.50% | 45.25% |
| **(15, 05) ms** | 67.25% | 51.75% | 43.75% |


**Score-Accuracy**
| Metric | DTW | Cosine  | L2 |
| :--- | :---: | :---: | :---: |
| **(40, 20) ms** | 23.00% | 11.20% | 10.00% |
| **(25, 10) ms** | **24.25%** | 12.00% | 11.75% |
| **(15, 05) ms** | 23.25% | 11.75% | 9.75% |



### 结果分析

#### 相似度函数的选择

在实验结果中可以看到，在hit或是score任务中，**将DTW作为相似度函数的性能显著优于Cosine和L2**。由于音频信号在时间轴上具有非线性伸缩的特性。L2 和 Cosine 距离要求特征矩阵在时间维度上严格对齐，而 DTW 能够通过寻找最优路径来消除时间轴上的误差，从而更准确地衡量两个音频序列的相似度。

#### 不同帧长与帧移对比试验

不同帧长与帧移的选择同样会影响MFCC特征提取分类的准确。

**帧长决定了每次采样的窗口大小**，如果帧长过短，可能会赴法提取出具有辨识度的音色特征，频率细节有所缺失；过长的帧长会模糊掉短促的瞬态信号，导致快速变化的时域特征缺失，导致时间细节模糊。

**帧移决定了每次采样的密度大小**，如果帧移较小，采样频率高，能够捕捉到信号微小的演变过程，但会导致程序计算量大，特征维度高，也可能包含大量冗余信息，且更容易受到噪声的干扰；较大的帧移减少了采样的频率，加快了计算速度，但可能导致某一个关键短帧被遗漏或采样不足，导致信息有部分缺失。

可以看到，由于top10（top20）对分类的精度要求要比score的更低，因此在top10分类中最优结果出现在(帧长, 帧移)=(15, 5)ms时，而当使用score进行分类时（score的原理将在后文给出，类似于top1分类的精度要求），由于精度要求更高，MFCC特征提取效果越好对应的分类结果越好，因此最优结果出现在(帧长, 帧移)=(25, 10)ms时，同时当二者上升或下降时，分类的准确率都会降低，验证了上述得到的结果。

---

## 原理分析

### FFT实现函数

fft_loop函数实现了Radix-2 Cooley-Tukey FFT算法，将时间复杂度由DFT的\(O(n^2)\)降至\(O(nlogn)\)。

算法首先将输入序列进行位反转重排，将索引n的二进制表示反转后作为新的访问顺序，从而在后续的碟型运算中建立正确的数据顺序。

在重排结束后，算法通过逐级扩展的鲽形结构进行计算，第s级中，分组长度为\(m=2^s\)，每个蝶形计算如下：
\(u = X[ k ]\)
\(t = W_N^tX[k + \frac{N}{2}]\)
\(X[ k ] = u + t\)
\(X[k + \frac{N}{2}] = u - t\)
其中，旋转因子\( W_N^t = e^{-j\frac{2\pi}{N}t}\)

由此计算得到离散序列的时域表示，具体实现见./dsp/fft.py文件。


### MFCC特征提取

MFCC特征提取共经过以下几个步骤：
预加重 -> 分帧加窗 -> STFT -> 功率谱计算 -> Mel 滤波器组映射 -> 对数压缩 -> DCT

对于输入的信号，我们首先用scipy.io.wavfile.read函数对ESC-50数据集中的所有音频进行读取，转化为torch.Tensor类型并加载到gpu上，使用预加重公式:

\[signal[ i ] = signal[ i ] - alpha * signal[ i-1 ]\]

对原始时域数据进行处理，随后根据设定的frame-time、hop-time对数据进行加窗分帧，公式为\(x_m[n ] = x[ n+mT]w[ n]\)，这里传入的frame-time、hop-time的的单位均为s，转换为点个数需要再与采样率相乘，窗函数w[n ]使用汉明窗。

随后进行短时傅里叶变化stft，本质上是对加窗分帧处理好的较短的数据切片进行DFT，**对每个切片我们都取绝对值，防止负值的干扰**，公式为\(X_N[m, k] = \sum_{n=0}^{N-1}x_m[n ]e^{-j\frac{2\pi k}{N}}n = \mathcal{DFT}(x_m[n ])\)，最后取模值返回便于后续计算，具体代码实现见./dsp/stft.py文件。

由于人耳对声音的感知更接近于对能量或响度的感知，而非对瞬时振幅的线性感知，因此需要对得到的特征计算功率谱，而\(P_i(k) = |X_i(k)^2|\)，因此**直接对得到的stft特征平方得到功率谱**，为后续的 Mel 滤波、对数压缩和倒谱分析提供合理而稳定的输入基础。

人类听觉系统对频率的感知并非线性关系。为模拟这一特性，MFCC 引入 Mel 频率刻度，其与频率hz的映射关系定义为：\(mel(f) = 2595log_{10}(1 + \frac{f}{700})\)。首先在 Mel 频率轴上等间距采样 \(n_{mel}+2\)（**第一个滤波器的分段点为0, 1, 2；第M个滤波器的分段点为M-1, M, M+1，因此需要采0 - M+1共M+2个点**） 个点，并将其映射回 Hz 频率，再对应至 FFT 频谱的 bin 索引。基于这些索引构建一组三角形带通滤波器，使得每个滤波器仅对特定频段的能量敏感。对于第 m 个 Mel 滤波器，其响应函数为分段线性函数：
$
H_m(k) = \begin{cases} 
\frac{k-b_{m-1}}{b_m-b_{m-1}}, & b_{m-1} \le k < b_m, \\
\frac{b_{m+1}-k}{b_{m+1}-b_m}, & b_m \le k < b_{m+1}, \\
0, & \text{otherwise.}
\end{cases}
$
将功率谱与 Mel 滤波器组相乘并求和，可得到 Mel 频带能量表示。


同时，考虑到人类对响度的感知近似符合对数规律，对 Mel 能量进行对数压缩：\(\hat{E}_i(m) = log(E_i(m))\)，随后，经过 DCT 将能量从滤波器域映射到倒谱域，公式为：
\[C_i(n) = \sum_{m=0}^{M-1}\hat{E}_i(m)cos [\frac{\pi n (2m+1)}{2M}] \]

最终，将提取到的MFCC特征矩阵保存为pt文件，便于后续更换不同相似函数评测时加速。


<!-- ### 项目可能可以讲的亮点？

* 手动实现的fft与mfcc变换（./dsp中的函数文件），我在上面的 **MFCC特征提取**板块进行了大致的原理讲解，大伙如果有更好的实现方法可以适当替换一下内容（尤其是fft实现部分）

* MFCC特征计算一次后本地存储，便于加载，有助于多次的评测，提高实验效率？

* 一些代码实现上的细节，上文标黑部分（绝对值、功率谱之类的）？

* 不局限于top10与top20 hit的MFCC特征性能测试，自定义打分函数 function.py-classification(...)，对fold5进行测试分类，自定义打分公式如下：
\[
S(c) = \sum_{i\in \mathcal(N)_c} exp(-\alpha d_i) + \lambda \cdot exp(- \beta min_{i \in \mathcal{N}_c}d_i)
\]
其中，\(d_i\)为相似函数返回值（类似于距离，归一化便于比较），第一项确保距离越小的类得到的得分高，第二项单纯考虑每一个类中最近的距离，两者综合考虑为每一个在topk中出现的target打分，得分最高的就是fold5文件对应的类。（一定程度上处理了（1）错误类不是最近但出现较多导致分数高，分类错位的情况（2）top1只考虑第一个最近的类，可能后续有大量正确的类都排在前面但被拍死的情况（3）topk只要正确类出现命中就算正确的不严谨的情况） -->

